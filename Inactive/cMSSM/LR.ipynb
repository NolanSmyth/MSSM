{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f331631-5d05-4077-9f28-1d6b53899785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sklearn\n",
    "\n",
    "# visualization\n",
    "import seaborn\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import corner\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f435019-aba4-4cfb-b23a-8efbfec0756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lbi.models\n",
    "from lbi.nde import NeuralRatioEstimator, NeuralLikelihoodEstimator\n",
    "from lbi.sequential import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aea86cc-fd32-4c6b-abcc-043e49ea28bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'read_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0fc9e73ee929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/jt/data/Projects/MSSM/Inactive/cMSSM/dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mread_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'read_dataset'"
     ]
    }
   ],
   "source": [
    "import dataset\n",
    "import sklearn.preprocessing\n",
    "\n",
    "N = 30000\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler().fit(dataset.obs)\n",
    "param_scaler = sklearn.preprocessing.StandardScaler().fit(dataset.params)\n",
    "\n",
    "param_dim = dataset.params.shape[-1]\n",
    "obs_dim = dataset.obs.shape[-1]\n",
    "observation = torch.tensor([[np.log(0.12), 118.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f790e-7679-4a8f-aaa4-0defdcae9539",
   "metadata": {},
   "outputs": [],
   "source": [
    "corner.corner(dataset.params.numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6b531d-b9d0-4e6a-80dc-2f5179dc415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corner.corner(dataset.obs.numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc4cbf3-2ee0-44d6-a993-211439fa385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make multivariate uniform prior distribution\n",
    "priors = torch.distributions.Independent(torch.distributions.Uniform(low=torch.zeros(param_dim), \n",
    "                                                                     high=torch.ones(param_dim)), \n",
    "                                         reinterpreted_batch_ndims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b29182-6259-4a6a-b7f4-3964c014c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 128\n",
    "x_dim = obs_dim + param_dim\n",
    "\n",
    "layers = [['ResBlock', x_dim], ['SELU'], \n",
    "          ['ResBlock', x_dim*2], ['SELU'], \n",
    "          ['ResBlock', x_dim*4], ['SELU'], \n",
    "#           ['ResBlock', x_dim*3], ['SELU'], \n",
    "#           ['ResBlock', x_dim*4], ['SELU'], \n",
    "#           ['Linear', width, width], ['SELU'], \n",
    "          ['Linear', x_dim*8, width], ['SELU'], \n",
    "          ['Linear', width, 1]]\n",
    "model = lbi.models.Classifier(layers=layers)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4)\n",
    "nre = NeuralRatioEstimator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b003b2-4657-4585-93b0-923bbb1137ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "snre = Sequential(priors=priors, \n",
    "                  obs_data=observation, \n",
    "                  param_dim=param_dim, \n",
    "                  model=nre, \n",
    "                  optimizer=optimizer, \n",
    "                  scaler=scaler, \n",
    "                  param_scaler=param_scaler,\n",
    "                  log_dir='.',\n",
    "                  simulator=None, \n",
    "                  progress=True,\n",
    "                  max_n_epochs=1000,\n",
    "                  patience=2500,\n",
    "                  n_rounds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727bba79-9049-41e8-9150-a6d5da01d438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data\n",
    "print(\"Adding sims to sequential object\")\n",
    "snre.add_data(dataset.obs[:N], dataset.params[:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ef5b56-aa57-4b99-931d-f797b7e96352",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "print(\"Training model\")\n",
    "try:\n",
    "    global_step = snre.train(global_step=global_step)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "snre.model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6adbd30-c904-49a4-a1aa-2d7740642e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = 10000\n",
    "with torch.no_grad():\n",
    "    true_lps = snre.model.forward(snre.data['train_data'][:n_data], snre.data['train_params'][:n_data])\n",
    "    false_lps = snre.model.forward(snre.data['train_data'][:n_data], snre.data['train_params'][torch.randperm(n_data)])\n",
    "\n",
    "_, bins, _ = plt.hist(false_lps.numpy(), alpha=0.5, label='false log prob', bins=np.linspace(-50, 10, 100))\n",
    "plt.hist(true_lps.numpy(), alpha=0.5, bins=bins, label='true log prob')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a78bb93-dc7d-4df4-a615-141da1ddac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cf40b3-d205-4b00-9ef4-bcda77261890",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = snre.hmc(num_samples=200000, walker_steps=10000, burn_in=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f20e62-35be-483d-a2cb-23623227185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corner.corner(posterior_samples.numpy(), \n",
    "              range=[(0, 1) for i in range(param_dim)], \n",
    "              smooth=0.1,\n",
    "             );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee53f3c-a2c4-4cd2-a646-1f99faf206f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = snre.hmc(num_samples=200000, walker_steps=5000, burn_in=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29549de9-bee8-437d-a535-2a744edbab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corner.corner(posterior_samples.numpy(), \n",
    "              range=[(0, 1) for i in range(param_dim)], \n",
    "              smooth=0.1,\n",
    "             );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f666a5ef-2ef3-4a06-8c9e-0a9ffd9ebe51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mssm",
   "language": "python",
   "name": "mssm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
